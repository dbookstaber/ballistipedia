{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Statistics for Ballistics\n",
    "\n",
    "This notebook provides an overview of the probability distributions and statistical techniques used to model and analyze ballistic precision.  It leverages Monte Carlo simulations to validate and demonstrate the math.  The notebook covers the following:\n",
    "\n",
    "1. **Normal Distribution**: Explores the Normal distribution, which models variables like muzzle velocity and shot dispersion along a single axis. It demonstrates how to estimate the mean and variance parameters from sample data, and to compute confidence intervals for these estimates.\n",
    "\n",
    "2. **Normal Distribution in 2 Dimensions**: Extends the Normal distribution to two dimensions, which is applicable for modeling the coordinates of hits on a target. It discusses the assumptions and tests for equal variances in the horizontal and vertical directions.\n",
    "\n",
    "3. **Rayleigh Distribution**: Introduces the Rayleigh distribution, which models the radial dispersion of shots from the center of impact when the horizontal and vertical variances are equal. It shows how to estimate the Rayleigh parameter and compute confidence intervals.\n",
    "\n",
    "4. **Sampling Distributions**: Explains the concept of sampling distributions and how to generate them through Monte Carlo simulation. This approach is particularly useful for statistics without closed-form expressions, like Extreme Spread (a.k.a. Group Size).\n",
    "\n",
    "5. **Statistical Tests**: Covers statistical tests for comparing the mean, variance, and/or precision of two different samples or populations. It demonstrates how to calculate *p*-values, effect sizes, and confidence intervals for these tests, and validates the results through simulations.\n",
    "\n",
    "These techniques have been implemented for ballistic applications in [this Google Sheet](https://docs.google.com/spreadsheets/d/1i_trin4mHuTJI4HnAnPiVwJHMc0m0X09E7Ya7_aWGFQ/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code samples depend on the following imports and helper functions\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bartlett, chi2, f, norm, percentileofscore, t\n",
    "\n",
    "def CIstring(CI, digits: int=1):\n",
    "      return np.array2string(np.array(CI), precision=digits, floatmode=\"fixed\", separator=\", \")\n",
    "\n",
    "def cGauss(n: int) -> float:\n",
    "    return math.exp(math.lgamma((n-1)/2) - math.lgamma(n/2) - math.log(math.sqrt(2/(n-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution in 1 dimension\n",
    "\n",
    "The ballistic trajectory of bullets fired from the same gun at the same point have some variation from shot to shot.  We can stick a target along the trajectory to record the coordinates of each shot.  When we look at the horizontal and vertical coordinates of where each shot hits the target we find that those coordinates follow the Normal distribution.  The Normal distribution also models another variable of interest in ballistics: Muzzle velocity, which is the speed at which bullets leave the gun.\n",
    "\n",
    "The Normal distribution has a bell curve shape that models the frequency of values that we can expect to observe from a Normal random process.  The Normal distribution is quantified by two *parameters*: mean ($\\mu$), and variance ($\\sigma^2$) or standard deviation ($\\sigma$).  These parameters determine the peak and spread of the bell curve.  $\\mathcal{N}(\\mu, \\sigma)$ denotes a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\n",
    "Following is a graph of the standard Normal distribution density $\\mathcal{N}(0, 1)$, showing the frequency of values from -3 to 3.  (The tails extend to infinity in each direction, but more than 99% of values fall within $\\pm 3\\sigma$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-3, 3, 0.1)\n",
    "pdf = norm.pdf(x, 0, 1)\n",
    "plt.plot(x, pdf)\n",
    "plt.title(\"Standard Normal Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency of Value\")\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to use the Normal distribution to model a specific random variable of interest – e.g., the muzzle velocity of a batch of ammunition, or the x-coordinates of bullet holes in a target – we have to determine the mean and variance that apply to that variable.\n",
    "\n",
    "### [Determining Mean and Variance](https://docs.google.com/spreadsheets/d/1i_trin4mHuTJI4HnAnPiVwJHMc0m0X09E7Ya7_aWGFQ)\n",
    "Typically when we look at a real-world random variable we don't know what the true distribution parameters are.  We can only estimate the parameters by studying samples of the values actually produced by the variable.\n",
    "\n",
    "Let's consider the muzzle velocity $V$ of a particular gun shooting a particular lot of ammunition.  We assume (based on general arguments of physics and statistics that we won't get into here) that muzzle velocity is a Normally distributed random variable – i.e., $V \\sim \\mathcal{N}(\\mu_V, \\sigma_V)$.  At the outset we don't know the value of those parameters, $\\mu_V$ and $\\sigma_V$.  To find them we begin to collect data: We have a chronograph to measure the muzzle velocity of each shot, so we can keep shooting to collect sample muzzle velocity values {${v_i} = v_1, v_2, ...$}.\n",
    "\n",
    "#### Estimating Mean\n",
    "Our best estimate of the true mean value is just the mean value of the samples.  I.e., given $n$ samples we estimate:\n",
    "\n",
    "$$\\hat{\\mu_V} = \\bar{v}= \\frac{\\sum{v_i}}{n}$$\n",
    "\n",
    "*Notation:*\n",
    "* A straight line over a variable denotes the mean value (a.k.a., average) of the variable.  So $\\bar{v}$ is the mean of all observed values {$v$}.\n",
    "* A hat over a variable means that it is an estimate.  So $\\hat{\\mu_V}$ is an estimate of the true (but typically unknown) $\\mu_V$.\n",
    "\n",
    "#### Estimating Variance\n",
    "Our best estimate of the true variance is:\n",
    "\n",
    "$$\\hat{\\sigma}^2 = s^2 = \\frac{1}{n-1}\\sum{(v_i - \\bar{v})^2}$$\n",
    "\n",
    "*Notation:* A convention particular to variance and standard deviation is to use the letter $s$ to denote an estimate of $\\sigma$, so $s = \\hat{\\sigma}$.\n",
    "\n",
    "#### Estimating Standard Deviation (SD)\n",
    "Given the true value of the variance, the standard deviation $\\sigma$ is just the square root of variance $\\sigma^2$: i.e.,  $\\sigma = \\sqrt{\\sigma^2}$.  But when estimating these parameters based on samples there is some bias produced by taking the square root, and that bias can be significant when the number of samples is small.  The bias is always an underestimate, so $\\hat{\\sigma} < \\sigma$.\n",
    "\n",
    "To remove the bias we need a correction factor: In the case of the Normal distribution we can use the Gaussian correction term $c_G(n)$, which depends on the number of samples used to compute the estimate:\n",
    "$$c_G(n) = \\sqrt{\\frac{n-1}{2}}\\,\\,\\,\\frac{\\Gamma\\left(\\frac{n-1}{2}\\right)}{\\Gamma\\left(\\frac{n}{2}\\right)}$$\n",
    "\n",
    "and our unbiased estimate of standard deviation is:\n",
    "$$\\hat{\\sigma} = c_G(n)\\sqrt{s^2}$$\n",
    "\n",
    "$c_G(n)$ is always > 1, but asymptotes quickly to 1 as $n$ increases.  When $n=2$ the uncorrected estimate is, on average, 20% too low; but by the time $n > 10$ the bias is less than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n= 2: cG(n)=1.2533',\n",
       " 'n= 3: cG(n)=1.1284',\n",
       " 'n= 4: cG(n)=1.0854',\n",
       " 'n= 5: cG(n)=1.0638',\n",
       " 'n= 6: cG(n)=1.0509',\n",
       " 'n= 7: cG(n)=1.0424',\n",
       " 'n= 8: cG(n)=1.0362',\n",
       " 'n= 9: cG(n)=1.0317',\n",
       " 'n=10: cG(n)=1.0281',\n",
       " 'n=11: cG(n)=1.0253']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Gaussian correction term cG(n) and show the first 10 values\n",
    "def cGauss(n: int) -> float:\n",
    "    return math.exp(math.lgamma((n-1)/2) - math.lgamma(n/2) - math.log(math.sqrt(2/(n-1))))\n",
    "[(f'n={i:2}: cG(n)={cGauss(i):.4f}') for i in range(2,12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence in Estimates\n",
    "\n",
    "An essential part of statistics is quantifying the *certainty* of an estimate.  Suppose we are trying to estimate the mean value of $V$.  I collect three samples and report my estimate as the average those three observations.  You collect thirty samples and report your estimate as the average of those thirty observations.  Clearly your estimate will have less uncertainty than mine.\n",
    "\n",
    "We can quantify uncertainty in estimates with **Confidence Intervals**.\n",
    "\n",
    "The formal definition of a Confidence Interval (CI) for an estimate of a parameter $\\theta$ is: an interval $(u, v)$ such that $P(u < \\theta < v) = \\gamma$.  The CI is always a function of the observations that produced the estimate, therefore the boundary values $(u, v)$ are a function of those particular observed values.  That is, *the CI is an interval calculated in such a way that, over many experiments, the probability that the CI contains the true parameter is $\\gamma$*.\n",
    "\n",
    "We can calculate a Confidence Interval for any probability $\\gamma \\in (0,1)$.  Confidence Intervals are typically calculated for probabilities of $\\gamma =$ 90% or 95%.  $\\gamma$ is sometimes referred to as the *confidence level*.\n",
    "\n",
    "A CI depends on the data used to generate the estimate.  So, for example, you and I may arrive at identical estimates for $\\hat{\\mu_V}$, but if you used ten times as many samples then your CI is going to be much smaller, indicating a higher certainty of what the true parameter is.\n",
    "\n",
    "***Caution:*** The term \"confidence\" is often misused, so to understand precisely what is being described by a Confidence Interval let's consider an example: Let $X$ be a random variable with some unknown parameter.  For example, the average muzzle velocity of a box of ammunition.  Now do an experiment:\n",
    "* Collect $n$ samples of $X$.\n",
    "* Compute the parameter estimate.  (For example, estimated mean $\\bar{x} = \\frac{\\sum{x_i}}{n}$.)\n",
    "* Compute the Confidence Interval for confidence level $\\gamma$ of that estimate: [$\\bar{x}_L, \\bar{x}_U$].  (Again: the CI depends on the particular samples we observe, so it will be different each time we run this experiment!)\n",
    "\n",
    "The Confidence Interval definition says: If we repeat this experiment many times then we will find that the Confidence Interval contains the true value of the parameter in exactly $\\gamma$ of the experiments.  (This also means that the CI does not contain the true value of the parameter in $(1-\\gamma)$ of the experiments.  So if we are computing 90% confidence intervals, then in 10% of experiments the CI will not contain the true value we are estimating!)\n",
    "\n",
    "How do we know the *true* value of the parameter we're estimating?  In practice we typically do not, which is the whole point of doing experiments and making estimates.  But we can verify that the math is correct by doing controlled experiments in which we do know the true value.  We will do that in the **Validation** sections.\n",
    "\n",
    "### Confidence Interval for Mean\n",
    "The Confidence Interval on the estimated mean $\\bar{x}$ of a Normally distributed random variable $X$ is:\n",
    "$$\\bar{x} \\pm t_{\\frac{1-\\gamma}{2},n-1} \\ \\sqrt{\\frac{s^2}{n}} \\ \\ = \\ \\ \\left[\\bar{x}+t_{\\frac{1-\\gamma}{2},n-1} \\ \\sqrt{\\frac{s^2}{n}}, \\ \\ \\ \\bar{x}-t_{\\frac{1-\\gamma}{2},n-1} \\ \\sqrt{\\frac{s^2}{n}}\\right]$$\n",
    "The key terms here come from:\n",
    "* The *t*-distribution: $t_{\\alpha,n-1}$ denotes the $\\alpha$ quantile of the *t*-distribution with $(n-1)$ degrees of freedom.  The spreadsheet function for this is `=T.INV(α, n-1)`.\n",
    "  * The unwieldy term $\\frac{1-\\gamma}{2}$ is often denoted by alpha ($\\alpha$).  The alpha term takes us to boundaries of the distribution for the given confidence level $\\gamma$.  If $\\gamma=$ 90%, then $\\alpha=$ 5% because we want the boundaries on the center 90% of the distribution, which is the region between 5% and 95%.\n",
    "* The *standard error of the mean*, which is $\\sqrt{\\frac{s^2}{n}}$.  (I put that in terms of $s^2$ instead of $s$ to make it clear that the bias correction factor is not needed here.)\n",
    "\n",
    "An important consequence of the latter term is that, holding all else equal, **the uncertainty in estimating the mean decreases with the square root of the number of samples**.  So, for example: to cut the uncertainty around an estimated mean by a factor of 2, we need to collect 4 times as many samples.\n",
    "\n",
    "### Confidence Interval for Variance\n",
    "Here is the formula for the Confidence Interval on the estimated variance $s^2$ of a Normally-distributed random variable:\n",
    "$$\\left[\\frac{(n-1)s^2}{\\chi^2_{\\frac{1+\\gamma}{2},n-1}},\\frac{(n-1)s^2}{\\chi^2_{\\frac{1-\\gamma}{2},n-1}}\\right]$$\n",
    "The key term here comes from the $\\chi^2$-distribution with $(n-1)$ degrees of freedom.  The spreadsheet function for this is `=CHIINV(α, n-1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "The following code simulates a single experiment and shows how to calculate the estimates and confidence intervals for a Normal variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We generated 10 sample values from a Normal(3000, 20) random variable.\n",
      "\tEstimates and 90% confidence intervals (CI):\n",
      "\t\tSample mean=3006.0 with CI=[2996.9, 3015.0]\n",
      "\t\tSample var = 241.6 with CI=[128.5, 653.8]\n",
      "\t\tSample SD  = 15.98 with CI=[11.3, 25.6]\n"
     ]
    }
   ],
   "source": [
    "mean = 3000  # True parameter value for simulation\n",
    "SD = 20      # True parameter value for simulation\n",
    "n = 10       # Number of samples to take\n",
    "gamma = 0.9  # Confidence level for Confidence Intervals\n",
    "samples = np.random.normal(loc=mean, scale=SD, size=n)\n",
    "sampleMean = np.mean(samples)\n",
    "sampleVariance = np.var(samples, ddof=1)\n",
    "sampleSD_biased = math.sqrt(sampleVariance)\n",
    "sampleSD = cGauss(n) * sampleSD_biased\n",
    "stdErr = sampleSD_biased/math.sqrt(n)\n",
    "confidenceMean = np.array(t.interval(gamma, df=n-1, loc=sampleMean, scale=stdErr))\n",
    "confidenceVar = np.divide((n-1)*sampleVariance, chi2.interval(gamma, df=n-1))[::-1]\n",
    "confidenceSD = np.sqrt(confidenceVar)\n",
    "\n",
    "print(f'We generated {n} sample values from a Normal({mean}, {SD}) random variable.\\n'\n",
    "      f'\\tEstimates and {gamma:.0%} confidence intervals (CI):\\n'\n",
    "      f'\\t\\tSample mean={sampleMean:.1f} with CI={CIstring(confidenceMean)}\\n'\n",
    "      f'\\t\\tSample var = {sampleVariance:.1f} with CI={CIstring(confidenceVar)}\\n'\n",
    "      f'\\t\\tSample SD  = {sampleSD:.2f} with CI={CIstring(confidenceSD)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation by Simulation\n",
    "\n",
    "When we simulate experiments using a random number generator (RNG), we tell the RNG what distribution and parameters to follow, so we know what the true parameters are.\n",
    "\n",
    "We can verify that our statistical formulas are correct by running many simulations:  As the number of simulations increases, we should find that our estimates get increasingly close to the true values.  (This computational technique is known as *Monte Carlo* simulation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 20,000 simulations of 5-sample groups from N(3000, 20), with 90% confidence intervals:\n",
      "\tAvg sample mean = 3000.0.  True mean was in the CI 89.6% of the time.\n",
      "\tAvg sample var = 401.0.  True variance was in the CI 90.0% of the time.\n",
      "\tAvg biased SD = 18.82.  Avg unbiased SD = 20.00.\n",
      "\t\tTrue SD was in the Sqrt(variance CI) 90.0% of the time.\n"
     ]
    }
   ],
   "source": [
    "mean = 3000  # True parameter value for simulation\n",
    "SD = 20      # True parameter value for simulation\n",
    "n = 5        # Number of samples per simulation\n",
    "gamma = 0.9  # Confidence level for which we want Confidence Intervals\n",
    "numSims = 20_000  # Number of simulations to run\n",
    "variance = SD**2\n",
    "cG = cGauss(n)\n",
    "chi2Interval = np.divide((n-1), chi2.interval(gamma, df=n-1))[::-1]\n",
    "samples = np.random.normal(loc=mean, scale=SD, size=(numSims, n))\n",
    "sampleMean = np.zeros(numSims)\n",
    "sampleVariance = np.zeros(numSims)\n",
    "sampleSD_biased = np.zeros(numSims)\n",
    "sampleSD = np.zeros(numSims)\n",
    "countMeanInInterval = 0  # Count when CI contains the true mean\n",
    "countVarInInterval = 0  # Count when CI contains the true variance\n",
    "countSD_InInterval = 0  # Count when CI contains the true SD\n",
    "\n",
    "for i in range(numSims):\n",
    "    sampleMean[i] = np.mean(samples[i])\n",
    "    sampleVariance[i] = np.var(samples[i], ddof=1)\n",
    "    sampleSD_biased[i] = math.sqrt(sampleVariance[i])\n",
    "    sampleSD[i] = cG * sampleSD_biased[i]\n",
    "    stdErr = sampleSD_biased[i]/math.sqrt(n)\n",
    "    confidenceMean = np.array(t.interval(gamma, df=n-1, loc=sampleMean[i], scale=stdErr))\n",
    "    if confidenceMean[0] < mean < confidenceMean[1]:\n",
    "        countMeanInInterval += 1\n",
    "    confidenceVar = sampleVariance[i] * chi2Interval\n",
    "    if confidenceVar[0] < variance < confidenceVar[1]:\n",
    "        countVarInInterval += 1\n",
    "    if math.sqrt(confidenceVar[0]) < SD < math.sqrt(confidenceVar[1]):\n",
    "        countSD_InInterval += 1\n",
    "\n",
    "print(f'Over {numSims:,} simulations of {n}-sample groups from N({mean}, {SD}), with {gamma:.0%} confidence intervals:\\n'\n",
    "      f'\\tAvg sample mean = {np.mean(sampleMean):.1f}.  True mean was in the CI {countMeanInInterval/numSims:.1%} of the time.\\n'\n",
    "      f'\\tAvg sample var = {np.mean(sampleVariance):.1f}.  True variance was in the CI {countVarInInterval/numSims:.1%} of the time.\\n'\n",
    "      f'\\tAvg biased SD = {np.mean(sampleSD_biased):.2f}.  Avg unbiased SD = {np.mean(SD):.2f}.\\n'\n",
    "      f'\\t\\tTrue SD was in the Sqrt(variance CI) {countSD_InInterval/numSims:.1%} of the time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution in 2 dimensions\n",
    "\n",
    "When looking at shots on a target, there are two variables that follow the Normal distribution: The location of each shot on the horizontal \"x\" axis (the *x coordinate*) and on the vertical \"y\" axis (the *y coordinate*).\n",
    "\n",
    "(In ballistics we do not see correlation between the *x-* and *y-* coordinates, so correlation and covariances between these two variables are always zero.)\n",
    "\n",
    "Though we often find that $\\sigma_x = \\sigma_y$, this is not necesssarily the case.  So how do we determine whether $\\sigma_x = \\sigma_y$?\n",
    "\n",
    "There are statistical tests for this, but they are not very powerful on the sample sizes typically available to shooters.  When it comes to ballistics, we know what phenomena can cause asymmetric variance: variable crosswinds cause excess horizontal variance, and variations in muzzle velocity cause excess vertical variance at longer ranges.  Using a ballistic calculator we can check whether the variation in crosswind or muzzle velocity are large enough to show up as excess variance on a target for the gun and distance we are shooting.  We can even use a calculator to remove those factors.  Excluding those factors, or when looking at short ranges where they won't show up (for example, at 100 yards for supersonic projectiles) it is reasonable to assume that $\\sigma_x = \\sigma_y$ unless these physics tell us that we should expect them to be significantly unequal.\n",
    "\n",
    "### Test for equal variances\n",
    "Following code shows two standard tests for equal variance (a.k.a., *homoscedasticity*): The F-test and Bartlett's test.  These tests return a *p*-value, which is *the probability of observing a difference at least as large as that found in the sample data when the reality is that the variances are equal*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample VarX=0.71 with 90% confidence interval [0.4, 1.9]\n",
      "Sample VarY=2.89 with 90% confidence interval [1.5, 7.8]\n",
      "F-test gives p=4.8%\n",
      "Bartlett gives p=4.8%\n"
     ]
    }
   ],
   "source": [
    "# Tests for equality of variances\n",
    "n = 10  # Number of samples to draw from each random variable\n",
    "gamma = .9\n",
    "chi2Interval = np.divide((n-1), chi2.interval(gamma, df=n-1))[::-1]\n",
    "sigmaX = 1.0  # We get to choose the sigmas so we can see how the tests behave\n",
    "sigmaY = 1.5  #  as we vary the difference between sigmaX and sigmaY.\n",
    "X = np.random.normal(scale=sigmaX, size=n)\n",
    "Y = np.random.normal(scale=sigmaY, size=n)\n",
    "varX = np.var(X, ddof=1)\n",
    "varY = np.var(Y, ddof=1)\n",
    "confidenceVarX = varX * chi2Interval\n",
    "confidenceVarY = varY * chi2Interval\n",
    "F = varX / varY\n",
    "p_valueF = 2 * f.cdf(F, n-1, n-1)  # Two-tailed F-test\n",
    "bstat, p_valueB = bartlett(X, Y)\n",
    "print(f'Sample VarX={varX:.2f} with {gamma:.0%} confidence interval {CIstring(confidenceVarX)}\\n'\n",
    "      f'Sample VarY={varY:.2f} with {gamma:.0%} confidence interval {CIstring(confidenceVarY)}\\n'\n",
    "      f'F-test gives p={p_valueF:0.1%}\\n'\n",
    "      f'Bartlett gives p={p_valueB:0.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of assuming $\\sigma_x = \\sigma_y$ is that we only have to work with a single parameter ($\\sigma$) when measuring and describing precision.  And with fewer parameters to estimate, we get more certainty from the same amount of data.\n",
    "\n",
    "### If we erroneously assume equal variances\n",
    "\n",
    "If we incorrectly assume $\\sigma_x = \\sigma_y$, then our predictions will have some error.  However, that error is small when the variances are not wildly different.  (This is detailed in BallisticSimulations.ipynb under *§Error from single sigma estimate*.)\n",
    "\n",
    "## Rayleigh Distribution\n",
    "\n",
    "If we treat the variances as equal, then we only have to deal with a single parameter $\\sigma$.  And if we only care about the dispersion of shots then we can use the Rayleigh distribution.  In formal terms: If the coordinate variables $X, Y$ are independent and Normally distributed with variance $\\sigma^2$, then the distance of each point from the sample center of impact is $r_i = \\sqrt{(x_i-\\bar{x})^2 + (y_i-\\bar{y})^2}$ and that variable $R$ follows the Rayleigh distribution with parameter $\\sigma$.  We will get a lot of mileage out of this fact because the Rayleigh distribution is relatively simple and well studied.  We will also benefit from the fact that $R^2$ follows the Exponential distribution with scale parameter $\\frac{\\sigma^2}{2}$.\n",
    "\n",
    "The Rayleigh parameter works like a standard deviation, and estimates of it have a bias just like estimates of SD.  In fact, we use the same correction function $c_G$ to correct the bias in Rayleigh estimates.  (The effective number of samples is reduced by 2 when we have to estimate the center of impact from the sample data.  And when using samples from multiple groups with unknown centers we have to remove 2 degrees for each group, which is why the number of groups $g$ appears in the formulas.)\n",
    "\n",
    "Given $n$ sample shots from $g$ groups, where $g$ is the number of sample centers that need to be estimated, the unbiased estimate of the Rayleigh parameter is:\n",
    "\n",
    "$$\\hat{\\sigma} = c_G(2(n-g)+1) \\sqrt{\\frac{\\sum{}(x_i-\\bar{x})^2 + (y_i-\\bar{y})^2}{2(n-g)}}$$\n",
    "\n",
    "The confidence interval on that estimate is:\n",
    "\n",
    "$$\\left[ \\ \\sqrt{\\frac{\\sum{}r_i^2}{\\chi^2_{\\frac{1+\\gamma}{2},2(n-g)}}}, \\sqrt{\\frac{\\sum{}r_i^2}{\\chi^2_{\\frac{1-\\gamma}{2},2(n-g)}}} \\ \\right]$$\n",
    "\n",
    "#### Validation of Rayleigh Estimate and CI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 100,000 simulations of 2 groups of 3 shots with sigma=2:\n",
      "\tMean estimate of sigma = 2.001\n",
      "\tTrue sigma was in the 90% confidence interval 90.1% of the time.\n"
     ]
    }
   ],
   "source": [
    "numSims = 100_000\n",
    "sigma = 2     # True parameter value for simulation\n",
    "n = 3         # Number of sample \"shots\" per group\n",
    "g = 2         # Number of sample \"groups\" per simulation\n",
    "gamma = 0.9   # Confidence level for Confidence Intervals\n",
    "\n",
    "count_contains_true_sigma = 0\n",
    "sigmaEstimate = np.zeros(numSims)\n",
    "sumR2 = np.zeros(numSims)\n",
    "degrees = 2*(n-1)*g\n",
    "cG = cGauss(degrees+1)\n",
    "chi2Upper = 1/chi2.ppf((1-gamma)/2, degrees)\n",
    "chi2Lower = 1/chi2.ppf((1+gamma)/2, degrees)\n",
    "shots = np.random.normal(scale=sigma, size=(numSims, g, n, 2))\n",
    "\n",
    "for s in range(numSims):\n",
    "    for j in range(g):\n",
    "        xbar = ybar = 0\n",
    "        for i in range(n):\n",
    "            xbar += shots[s, j, i, 0]\n",
    "            ybar += shots[s, j, i, 1]\n",
    "        xbar /= n\n",
    "        ybar /= n\n",
    "        for i in range(n):\n",
    "            sumR2[s] += (shots[s, j, i, 0] - xbar)**2 + (shots[s, j, i, 1] - ybar)**2\n",
    "    sigmaEstimate[s] = cG * math.sqrt(sumR2[s] / degrees)\n",
    "    CL = math.sqrt(sumR2[s]*chi2Lower)\n",
    "    CU = math.sqrt(sumR2[s]*chi2Upper)\n",
    "    if CL < sigma < CU:\n",
    "        count_contains_true_sigma += 1\n",
    "\n",
    "print(f'Over {numSims:,} simulations of {g} groups of {n} shots with sigma={sigma}:\\n'\n",
    "      f'\\tMean estimate of sigma = {np.mean(sigmaEstimate):.3f}\\n'\n",
    "      f'\\tTrue sigma was in the {gamma:.0%} confidence interval'\n",
    "      f' {count_contains_true_sigma/numSims:.1%} of the time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Distributions\n",
    "\n",
    "When working with a common distribution (e.g., Normal or Rayleigh), we can often find formulas to compute statistics and confidence intervals.  Using a formula can simplify calculations and provide additional insights, since there is a great deal of ancillary knowledge associated with common distributions.\n",
    "\n",
    "An alternative to formulas is the brute-force computational approach of creating a *sampling distribution*.  This only requires that we have a model of the experiment that we can run (a.k.a., *simulate*) on a computer.  The computational approach generates the distribution by repeatedly feeding random numbers into the simulation, giving us the outcome of thousands or millions of virtual experiments.  The aggregation of those simulated experiments is called the *sampling distribution*, and when generated with a large number of simulations it becomes practically identical to the true distribution.\n",
    "\n",
    "## Range Statistics\n",
    "\n",
    "We don't have formulas for the distribution of range statistics like Extreme Spread (ES), so we will generate sampling distributions to get expected values, confidence intervals, and measures of efficiency.  The sampling distribution for ES depends on three parameters:\n",
    "\n",
    "1. Group size $n$: ES increases with the number of shots per group. \n",
    "2. Number of groups $g$: The average ES measured over multiple groups produces a tighter sampling distribution (which reflects higher certainty in the form of, inter alia, a lower Coefficient of Variation and narrower Confidence Intervals).\n",
    "3. Dispersion $\\sigma$: Our model simulates shots using bivariate Normal random numbers $X, Y \\sim \\mathcal{N}(0,\\sigma)$.\n",
    "\n",
    "The distribution of ES (and the other range statistics) is scale invariant: I.e., $\\text{ES}(n,g,c \\cdot \\sigma)=c\\cdot \\text{ES}(n,g,\\sigma)$.  (This follows from the scale property of the Normal distribution: $X \\sim \\mathcal{N}(\\mu,\\sigma) \\iff X \\sim \\sigma \\cdot \\mathcal{N}(\\mu,1)$.)  Therefore if we compute the sampling distribution for $\\text{ES}(n,g,\\sigma=1)$ then we can scale it by multiplying for any value of $\\sigma$.\n",
    "\n",
    "The following code computes the sampling distribution for $\\text{ES}(n,g,\\sigma=1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ES(n: int, shots: list[tuple[float, float]]) -> float:\n",
    "    \"\"\"Compute Extreme Spread for a group of n shots\"\"\"    \n",
    "    ES = 0\n",
    "    for shot in range(n):\n",
    "        for i in range(shot+1, n):\n",
    "            spread = (shots[shot][0]-shots[i][0])**2 + (shots[shot][1]-shots[i][1])**2\n",
    "            if spread > ES: ES = spread\n",
    "    return np.sqrt(ES)\n",
    "\n",
    "def samplingES(g: int, n: int, sigma: float=1, simulations: int=50_000) -> list[float]:\n",
    "    \"\"\"Generate sampling distribution of Extreme Spread for g groups of n shots per group\"\"\"    \n",
    "    shots = np.random.normal(scale=sigma, size=(simulations, g, n, 2)) # (x,y) coordinate of shots\n",
    "    ES = np.zeros(simulations)\n",
    "    for i in range(simulations):\n",
    "        for j in range(g):\n",
    "            ES[i] += group_ES(n, shots[i, j])\n",
    "        ES[i] /= g\n",
    "    return ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute statistics and confidence intervals for estimates directly from the sampling distribution.  By definition, the 90% confidence interval of an estimate is the range of values between the 5th and 95th percentile of the sampling distribution.  To apply this we normalize the sampling distribution by dividing it by its median value (so that the normalized median of the distribution is 1).  Then to get the CI for a particular estimate $\\widehat{ES}$ we multiply the normalized confidence interval by that estimate.  The following code demonstrates this process for the Extreme Spread of 5-shot groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Extreme Spread on a 5-shot group when sigma=1:\n",
      "\tMean=3.06\tMedian=3.01\tSD=0.82\n",
      "\tNormalized 90% Confidence Interval = [0.60, 1.49]\n",
      "Example: Random simulation with sigma=2 of a 5-shot group returns a sample ES=5.74\n",
      "\t90% Confidence Interval on this estimate = [3.44, 8.57]\n"
     ]
    }
   ],
   "source": [
    "ES5 = samplingES(1, 5)  # Distribution of ES when measured on 1 group of 5 shots\n",
    "ES5median = np.median(ES5)\n",
    "print(f'For Extreme Spread on a 5-shot group when sigma=1:')\n",
    "print(f'\\tMean={np.mean(ES5):.2f}\\tMedian={ES5median:.2f}\\tSD={np.std(ES5, ddof=1):.2f}')\n",
    "gamma = 0.9  # Confidence level\n",
    "ES5_CI = [np.percentile(ES5, 100*(1-gamma)/2)/ES5median, np.percentile(ES5, 100*(1+gamma)/2)/ES5median]\n",
    "print(f'\\tNormalized {gamma:.0%} Confidence Interval = {CIstring(ES5_CI, 2)}')\n",
    "sampleES5 = group_ES(5, np.random.normal(scale=2, size=(5,2)))\n",
    "print(f'Example: Random simulation with sigma=2 of a 5-shot group returns a sample ES={sampleES5:.2f}')\n",
    "print(f'\\t90% Confidence Interval on this estimate = {CIstring(np.multiply(sampleES5, ES5_CI),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the CI on ES estimates using 5-shot groups improves as we increase the number of groups sampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When estimating ES from 5-shot groups, the 90% CIs are:\n",
      "1 group CI = [0.60, 1.50]\t CI width=0.90\n",
      "2 group CI = [0.71, 1.34]\t CI width=0.63\n",
      "3 group CI = [0.76, 1.27]\t CI width=0.51\n",
      "4 group CI = [0.79, 1.23]\t CI width=0.45\n",
      "5 group CI = [0.81, 1.21]\t CI width=0.40\n"
     ]
    }
   ],
   "source": [
    "def ES_Confidence_Interval(g: int, n: int, gamma: float) -> tuple[float, float]:\n",
    "    sampling = samplingES(g, n)\n",
    "    median = np.median(sampling)\n",
    "    return [np.percentile(sampling, 100*(1-gamma)/2)/median, np.percentile(sampling, 100*(1+gamma)/2)/median]\n",
    "\n",
    "n = 5\n",
    "print(f'When estimating ES from {n}-shot groups, the {gamma:.0%} CIs are:')\n",
    "for groups in range(1, 6):\n",
    "    CI = ES_Confidence_Interval(groups, n, gamma)\n",
    "    print(f'{groups} group CI = {CIstring(CI, 2)}\\t CI width={CI[1]-CI[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the CI width of 4 sample groups is ½ the width of 1 sample, as expected since statistical uncertainty decreases with the square root of sample size.  (Ref §Statistical Uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Efficiency\n",
    "\n",
    "Suppose we want to test the precision of a new cartridge.  We go to a shooting range with a box of 20 rounds.  How can we get the most information on precision out of shooting those?  If we're going to measure the Extreme Spread of groups, is it better to sample 2 groups of 10 rounds, 4 groups of 5 rounds, or maybe even 10 groups of 2 rounds?\n",
    "\n",
    "Statistics gives us a precise answer to this question via a statistic called the Coefficient of Variation:  $$\\text{CV}=\\frac{\\sigma}{\\mu}$$\n",
    "\n",
    "(We get the mean and SD from the sampling distribution of the estimate.)\n",
    "\n",
    "Now consider two different methods of estimating $\\hat{\\sigma}$: Method A is to measure the ES of 5-round groups, and method B is to measure the ES of 2-round groups.  Once we know the CV of each method, we can compute thee efficiency of A relative to the efficiency of B:\n",
    "$$\\text{Relative Efficiency RE}=\\left(\\frac{\\text{CV}_A}{\\text{CV}_B} \\right)^2$$\n",
    "\n",
    "This RE tells us the number of samples using method A needed to match an estimate with the same certainty we can get from each one sample using method B:\n",
    "$$n_A = n_B \\times \\text{RE}$$\n",
    "\n",
    "However, for our purposes, what we consider a \"sample\" is not a group, but rather a single shot.  For example, we get one estimate of ES from a 5-shot group, but we spend five shots to get that estimate.  So we want to look at Relative Efficiency in terms of number-of-shots: $\\text{RE}=\\frac{n_A \\text{CV}_A^2}{n_B \\text{CV}_B^2}$.  The following code will get the actual CV of these two methods and compute this relative efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-shot ES CV = 0.268\t2-shot ES CV = 0.521\n",
      "Relative efficiency 5-shot vs 2-shot groups = 151.0%\n"
     ]
    }
   ],
   "source": [
    "def ES_CV(g: int, n: int):\n",
    "    sampling = samplingES(g, n)\n",
    "    return np.std(sampling, ddof=1)/np.mean(sampling)\n",
    "\n",
    "ES_CVx5 = ES_CV(1, 5)\n",
    "ES_CVx2 = ES_CV(1, 2)\n",
    "RE = (2*ES_CVx2**2 / (5*ES_CVx5**2))\n",
    "print(f'5-shot ES CV = {ES_CVx5:.3f}\\t2-shot ES CV = {ES_CVx2:.3f}')\n",
    "print(f'Relative efficiency 5-shot vs 2-shot groups = {RE:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative Efficiency, per shot, of 5-shot versus 2-shot groups is just about 150%, or 3:2.  So to match statistical certainty, we have to spend 3 shots shooting 2-shot groups for each 2 shots spent shooting 5-shot groups.  Let's verify this by checking the confidence intervals on ES estimated from two different experiments:\n",
    "1. Four 5-shot groups (20 shots total)\n",
    "2. Fifteen 2-shot groups (30 shots total)\n",
    "\n",
    "If our math is right then the normalized confidence intervals should have approximately the same width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4x5-shot groups CI is [0.79, 1.24] width = 0.45\n",
      "15x2-shot groups CI is [0.79, 1.23] width = 0.45\n"
     ]
    }
   ],
   "source": [
    "CI1 = ES_Confidence_Interval(4, 5, gamma)\n",
    "CI2 = ES_Confidence_Interval(15, 2, gamma)\n",
    "print(f' 4x5-shot groups CI is {CIstring(CI1, 2)} width = {(CI1[1]-CI1[0]):.2f}')\n",
    "print(f'15x2-shot groups CI is {CIstring(CI2, 2)} width = {(CI2[1]-CI2[0]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests\n",
    "\n",
    "The essence of the scientific process can be summarized as follows:\n",
    "\n",
    "1. Ask a question.\n",
    "2. Formulate a hypothesis – an answer to the question that could be either true or false.\n",
    "3. Collect data that address the truth of the hypothesis.\n",
    "4. Assess whether the data confirm the hypothesis.\n",
    "\n",
    "This process is complicated when the question involves something that exhibits random variation, which is what we will cover here.\n",
    "\n",
    "A typical question is, \"Does doing something have an effect?\"  In ballistics the *something* might be *using a different type of ammunition*, and the *effect* of interest might be *change the precision of the gun*.  For example, \"Is ammunition A more precise than ammunition B?\"  The scientific process to addressing that question boils down to, \"Test some of each and find out.\"  But, especially when the data include random variation, people are notoriously disposed to drawing unjustified conclusions.\n",
    "\n",
    "The field of Statistics provides mathematically rigorous techniques for determining precisely what data can say.  So in this section we're going to focus on doing statistical inference for simple A/B tests, in contexts where we know the probability distributions that apply to random variables in the question we're studying.  (In ballistics, the distribution that models variables like muzzle velocity and shot dispersion along any one axis is the Normal distribution.  Point of impact on a two-dimensional target follows a bivariate Normal distribution, which in many relevant scenarios reduces to the Rayleigh distribution.)\n",
    "\n",
    "Statistical testing begins with a peculiar formulation called the *null hypothesis*, which is denoted $H_0$.  A null hypothesis has to be a falsifiable assertion that we can unambiguously model.  In the context of an A/B question, a typical null hypothesis is, \"*There is no difference between A and B*.\"  Why choose that?  For one thing, if you can model just one of the two things then you can model that null hypothesis.  There's no ambiguity because there is only one way in which two variables can be identical, but an infinite number of ways for them to be different.  Further, the alternative to such a hypothesis is logically simple: If $H_0$ is false, then its complement $H_1 = {\\sim}H_0$ is true.  So, if $H_0$ is, \"*There is no difference between A and B*,\" then the *alternative hypothesis* $H_1$ is, \"*There is a difference between A and B*.\"\n",
    "\n",
    "After formulating the question and hypothesis, we collect data relevant to the hypothesis.  If necessary, we design and conduct an experiment to generate data.\n",
    "\n",
    "With data in hand, we arrive at the *test statistic*: a number computed from experimental data whose value depends on whether a hypothesis is true.  There is some art to constructing and selecting test statistics.  The following heuristics cover the situations we are studying:\n",
    "* When the question concerns *location* parameters like the Normal mean ($\\mu$) the best test statistic is the difference of estimates: ($\\hat{\\mu}_A - \\hat{\\mu}_B$)\n",
    "* When the question concerns *scale* parameters like the Normal SD ($\\sigma$) the best test statistic is the ratio of estimates: $\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B}$\n",
    "\n",
    "At this point we confront a fundamental problem: In any phenomenon that involves random variation, we will find statistical differences even when there is no actual difference (i.e., even when $H_0$ is true).  The challenge in statistical inference is to distinguish between experimental differences that appear when there is no true difference – i.e., random sample variation under $H_0$ – and differences that appear when $H_1$ is true.  Statistics gives us the following tools to guide our inferences from random variables:  \n",
    "\n",
    "* The ***p* value**, which is the probability of observing those data if the null hypothesis is correct.  Expressed another way: *When there is no real difference, **p** is the probability of observing a difference at least as large as what was found in this experiment*.  (This is also referred to as the probability of a \"type 1 error\" or \"false positive.\")\n",
    "\n",
    "* The **effect size**, which is an estimate of the difference between A and B *if the alternate hypothesis is correct*.  For example, if $\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B} = 2$ then we would say that *if we believe $H_1$* then we estimate that A has double the dispersion of B.\n",
    "\n",
    "* **Confidence Interval (CI) on the effect size**, which is a range around the estimated effect size that contains the true value in some proportion of experiments.  For example, if A really does have exactly 2 times the dispersion of B, and following each experiment we calculate the 90% confidence interval on the measured effect size, then in 90% of such experiments the computed confidence interval will contain the value 2.\n",
    "\n",
    "Until a few decades ago, many researchers ended their analysis with the *p* value.  But that can produce a variety of adverse and misleading results.  (Search the terms *p-hacking* and *data-dredging* for a taste.)  So statisticians have tried to increase the attention given to effect sizes and confidence intervals, as we do here.\n",
    "\n",
    "It is important to note that statistical inference can never definitively tell us which hypothesis is correct.  Rather, it precisely summarizes the weight of the evidence under each hypothesis.  What conclusion to draw or action to take is still a matter of individual preferences.  For example, if the cost of A and B are about the same then a shooter may decide to switch from A to B even if the *p* value is very high, because there is virtually no downside if the inferred benefit is a false positive.  On the other hand, if the cost of B is much higher than A, then a shooter might look for a very low *p* value and a tight confidence interval on a large effect before deciding to make the switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Precision shooters love ammunition that has low muzzle velocity variance.  We have been shooting a particular cartridge load \"A.\"  A friend said that he thinks a different gunpowder produces lower SD, so we put together a batch of cartridges with that powder and call it load \"B.\"\n",
    "\n",
    "Question: Is the velocity variance of B lower than that of A?\n",
    "\n",
    "1. The null hypothesis is that the variance of the two loads is identical.\n",
    "1. The experiment: We will shoot 20 rounds of each load over a chronograph and compute the sample variance $s^2$ of those 20 velocity measurements.\n",
    "1. The test statistic will be the ratio of the velocity variance estimates: $\\frac{s_A^2}{s_B^2}$\n",
    "\n",
    "# Ratio of Variances, Normal variables\n",
    "\n",
    "We want to know whether the variance of two Normally distributed variables is different.  Variance is a scale parameter so the test statistic will be the ratio of the variance estimates.  This is such a common test statistic that there is an established distribution for it: the F-distribution.\n",
    "\n",
    "If *X* and *Y* are Normally distributed, then the test statistic for a difference in variance under the null hypothesis is:\n",
    "$$\\frac{s_x^2}{s_y^2} \\sim F(n_x-1, n_y-1)$$\n",
    "\n",
    "## Check of Sampling Distribution\n",
    "The following code runs `numSims` simulations to generate the sampling distribution of this statistic.  The statistic depends on the number of samples of each variable, so we specify those at the beginning of the code as $n_x, n_y$.\n",
    "\n",
    "To check that the sampling distribution matches the F distribution we use a technique called the *Q-Q plot*: We scatter-plot the quantiles of the two distributions, and the distributions are identical if and only if the plotted points all sit on the line $y=x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx, ny = (15, 5)       # Experimental parameters – sample size for each variable\n",
    "numSims = 50_000       # Number of experiments to simulate\n",
    "R = np.zeros(numSims)  # Allocate array for each simulation's statistic value\n",
    "for i in range(numSims):\n",
    "    # Simulated experiment under H0:\n",
    "    x = np.random.normal(size=nx)  # Default scale parameter is 1; under H0 we only\n",
    "    y = np.random.normal(size=ny)  #  require that it is the same for both variables.\n",
    "    varX = np.var(x, ddof=1)\n",
    "    varY = np.var(y, ddof=1)\n",
    "    R[i] = varX/varY   # The test statistic for this simulation\n",
    "R.sort()  # Now sorted, R[] is the sampling distribution of the test statistic\n",
    "\n",
    "# Prepare Q-Q plot to compare sampling distribution with the F distribution\n",
    "r = np.linspace(0, 1, numSims, endpoint=False)  # Quantiles\n",
    "Q = f.ppf(r, nx-1, ny-1)  # Quantile values of the F distribution\n",
    "cut_tail = int(0.98 * numSims)  # Cut off the extreme right tail where we get a few huge values\n",
    "plt.scatter(R[:cut_tail], Q[:cut_tail], s=1)\n",
    "plt.xlabel('Sampling Distribution Q')\n",
    "plt.ylabel('F Distribution Q')\n",
    "plt.margins(x=0,y=0)\n",
    "plt.gca().set_aspect(1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that confirms that the sampling distribution matches the formulaic distribution.\n",
    "\n",
    "Now let's look at how to use the distribution (either one) to calculate the *p* value and confidence interval for this question.\n",
    "\n",
    "## CI and *p* for one experiment\n",
    "\n",
    "The *p* value comes directly from the distribution that models the statistic.  The formula to compute a confidence interval takes a little more work:\n",
    "\n",
    "The formula for the Confidence Interval on a ratio of sample variances, for Normal variables, is:\n",
    "\n",
    "$$\\frac{s_x^2}{s_y^2} \\ \\times \\left[ \\frac{1}{F_{\\frac{1+\\gamma}{2}}(n_x-1, n_y-1)}, \\frac{1}{F_{\\frac{1-\\gamma}{2}}(n_x-1, n_y-1)} \\right]$$\n",
    "\n",
    "The following code simulates one experiment and then shows how to compute both the *p* value and the CI using both the formulaic and the sampling distributions.  We will compute a two-tailed *p* value because the question we are addressing is whether the variances are *different*, and we want that to include not only scenarios where $s_x^2 > s_y^2$ (which would make the test statistic > 1) but also where $s_x^2 < s_y^2$ (which would make the test statistic < 1).  If we only cared about one of those variants we could exclude the *p* on the other side.  In this case we compute the tails separately because this test statistic can become quite asymmetric when $n_x$ is different from $n_y$.  (When distributions are symmetric we can get a two-tailed value by just doubling the value from one tail.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples VarianceX: 0.70 (n=15)\t VarianceY: 2.35 (n=5)\n",
      "\tSample Variance Ratio: 0.30\t(True Ratio: 1)\n",
      "90% Confidence Interval on Sample Ratio: [0.05, 0.92] from F-dist\n",
      "\t\t ... Confidence Interval [0.05, 0.92] from sampling distribution\n",
      "\t p value from sampling = 16.5%\n",
      "\t p value from F distribution = 16.4%\n"
     ]
    }
   ],
   "source": [
    "true_param = 1  # Simulation setting: True value of VarX/VarY\n",
    "gamma = 0.9     # Confidence level to compute\n",
    "\n",
    "# Run Experiment\n",
    "x = np.random.normal(size=nx, scale=np.sqrt(true_param))\n",
    "y = np.random.normal(size=ny)\n",
    "varX = np.var(x, ddof=1)\n",
    "varY = np.var(y, ddof=1)\n",
    "ratio = varX/varY\n",
    "\n",
    "# Right tail of p value\n",
    "p_right_from_sampling = 1-percentileofscore(R, ratio if ratio >= 1 else 1/ratio)/100\n",
    "p_right_from_F = 1-f.cdf(ratio if ratio >= 1 else 1/ratio, nx-1, ny-1)\n",
    "# Left tail of p value\n",
    "p_left_from_sampling = percentileofscore(R, ratio if ratio <= 1 else 1/ratio)/100\n",
    "p_left_from_F = f.cdf(ratio if ratio <= 1 else 1/ratio, nx-1, ny-1)\n",
    "\n",
    "# Compute confidence interval using F-distribution\n",
    "CU = ratio / f.ppf((1-gamma)/2, nx-1, ny-1)  # Upper bound of confidence interval\n",
    "CL = ratio / f.ppf((1+gamma)/2, nx-1, ny-1)  # Lower bound of confidence interval\n",
    "# Compute confidence interval using sampling distribution\n",
    "CUs = ratio / R[int(numSims * (1-gamma)/2)]  # Upper bound of confidence interval\n",
    "CLs = ratio / R[int(numSims * (1+gamma)/2)]  # Lower bound of confidence interval\n",
    "\n",
    "print(f'Samples VarianceX: {varX:.2f} (n={nx})\\t VarianceY: {varY:.2f} (n={ny})\\n'\n",
    "      f'\\tSample Variance Ratio: {varX/varY:.2f}\\t(True Ratio: {true_param})\\n'\n",
    "      f'{gamma:.0%} Confidence Interval on Sample Ratio: [{CL:.2f}, {CU:.2f}] from F-dist\\n'\n",
    "      f'\\t\\t ... Confidence Interval [{CLs:.2f}, {CUs:.2f}] from sampling distribution\\n'\n",
    "      f'\\t p value from sampling = {p_left_from_sampling+p_right_from_sampling:.1%}\\n'\n",
    "      f'\\t p value from F distribution = {p_left_from_F+p_right_from_F:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get virtually the same statistics whether we use the formula or the sampling distribution.  (Why not *exactly* the same?  In this case, with the sampling distribution based on 50,000 simulations, we may see a difference in the third order.  We can get the numbers to match to an arbitrary precision by increasing the number of simulations used to create the sampling distribution.  In other words, the sampling distribution converges to match the formulaic distribution as the number of simulations increases.)\n",
    "\n",
    "### Simulation to verify *p*\n",
    "\n",
    "How can we be sure that our statistical formulas and code are correct?\n",
    "\n",
    "We'll go right back to the definition of the *p* value: *The probability of observing a test statistic that is at least as extreme as the one observed in the experiment when $H_0$ is true.*\n",
    "\n",
    "Remember: If the null hypothesis $H_0$ is true then *X* and *Y* have the same distribution.  In this experiment we drew $n_x$ samples from *X* and $n_y$ samples from *Y* and then computed the test statistic (the ratio of their sample variances).  So to verify the *p* value we calculated above: we'll simulate a large number of such experiments with *X* and *Y* drawing from the same distribution and **count how many of the experiments give a test statistic that is at least as extreme as the one for which we computed the *p* value** above.  By definition, that proportion should match the calculated *p* value.\n",
    "\n",
    "Recall that for this example we computed a two-tailed value because we are looking for a difference in either direction.  So if one variance is twice as large as the other, then the ratio could be either 2/1 or 1/2, and if it's the former than \"more extreme\" means greater than 2, and if it's the latter than \"more extreme\" means less than 1/2.  To handle both tails, for each simulation we will check both the ratio and its inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the experimental variance ratio 0.30 and its inverse 3.37:\n",
      "\tF-dist gives p left tail = 4.0%, right tail = 12.5%, sum=16.4%\n",
      "Over 50,000 simulations with (nx=15, ny=5) using the null hypothesis:\n",
      "\t 4.0% produced a variance ratio < 0.30\n",
      "\t12.5% produced a variance ratio > 3.37\n",
      "\t16.4% produced a statistic more extreme than the experiment.\n"
     ]
    }
   ],
   "source": [
    "print(f'For the experimental variance ratio {ratio:.2f} and its inverse {1/ratio:.2f}:')\n",
    "print(f'\\tF-dist gives p left tail = {p_left_from_F:.1%}, right tail = {p_right_from_F:.1%},'\n",
    "      f' sum={p_right_from_F+p_left_from_F:.1%}')\n",
    "sample_ratio = ratio  # Ratio from single experiment above\n",
    "if sample_ratio < 1:  # Reference value will be the ratio in terms > 1\n",
    "    sample_ratio = 1/sample_ratio\n",
    "count_left = 0\n",
    "count_right = 0\n",
    "for i in range(numSims):\n",
    "    x = np.random.normal(size=nx)  # We're using the same distribution for both variables\n",
    "    y = np.random.normal(size=ny)  # since this is a simulation under the null hypothesis\n",
    "    simVarX = np.var(x, ddof=1)\n",
    "    simVarY = np.var(y, ddof=1)\n",
    "    simRatio = simVarX/simVarY\n",
    "    if simRatio > 1 and simRatio >= sample_ratio:\n",
    "        count_right += 1\n",
    "    elif simRatio < 1 and simRatio <= 1/sample_ratio:\n",
    "        count_left += 1\n",
    "print(f'Over {numSims:,} simulations with (nx={nx}, ny={ny}) using the null hypothesis:\\n'\n",
    "      f'\\t{count_left/numSims:5.1%} produced a variance ratio < {1/sample_ratio:.2f}\\n'\n",
    "      f'\\t{count_right/numSims:5.1%} produced a variance ratio > {sample_ratio:.2f}\\n'\n",
    "      f'\\t{(count_left+count_right)/numSims:.1%} produced a statistic more extreme than the experiment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in all probabilistic methods: the simulated results can differ slightly from the formulaic results, but they will converge as the number of simulations increases.  Here, with 50,000 simulations, we see some differences in the third figure.  Increase the number of simulations and those differences will disappear.\n",
    "\n",
    "### Simulation to verify CI formula\n",
    "We'll use the same method to verify the Confidence Interval (CI) formula.\n",
    "\n",
    "By definition, the Confidence Interval is *a range that contains the true parameter in exactly $\\gamma$ (gamma) proportion of the experiments*.  So we'll simulate many experiments, calculate the CI each time, and **count how many of the CIs contain the true parameter**.  (Here we know the true parameter because we are specifying it in the random number generator of the simulation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50,000 simulations of 15 samples for X and 5 samples for Y,\n",
      "\tthe 90% CI contained the true parameter 90.1% of the time.\n"
     ]
    }
   ],
   "source": [
    "true_param = 3  # True parameter VarX/VarY\n",
    "gamma = 0.9     # Desired confidence level\n",
    "FU = 1/f.ppf((1-gamma)/2, nx-1, ny-1)  # Upper bound of F dist\n",
    "FL = 1/f.ppf((1+gamma)/2, nx-1, ny-1)  # Lower bound of F dist\n",
    "count_contains_true = 0  # Number of simulations in which CI contains true parameter\n",
    "for i in range(numSims):\n",
    "    x = np.random.normal(size=nx, scale=np.sqrt(true_param))\n",
    "    y = np.random.normal(size=ny, scale=1)\n",
    "    varX = np.var(x, ddof=1)\n",
    "    varY = np.var(y, ddof=1)\n",
    "    ratio = varX/varY\n",
    "    CL = ratio * FL  # Confidence interval lower bound \n",
    "    CU = ratio * FU  # Confidence interval upper bound\n",
    "    if CL < true_param < CU:\n",
    "        count_contains_true += 1\n",
    "\n",
    "print(f'Over {numSims:,} simulations of {nx} samples for X and {ny} samples for Y,\\n\\t'\n",
    "      f'the {gamma:.0%} CI contained the true parameter {count_contains_true / numSims:.1%} of the time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference of Means, Normal variables\n",
    "\n",
    "We want to know whether the mean of two Normally distributed variables is different.  The mean is a location parameter so the test statistic will be the difference of the estimated means.  In the general case this turns out to be tricky:  If *X* and *Y* are Normally distributed, then the normalized difference of their estimated means is t-distributed with $\\nu$ (nu) degrees of freedom as follows:\n",
    "\n",
    "$$\\frac{\\bar{x} - \\bar{y}}{\\sqrt{\\epsilon_x+\\epsilon_y}} \\sim t(\\nu), \\ \\text{where:} \\ \\ \\nu=\\frac{(\\epsilon_x + \\epsilon_y)^2}{\\frac{\\epsilon_x^2}{n_x-1}+\\frac{\\epsilon_y^2}{n_y-1}}, \\ \\ \\ \\epsilon_i = \\frac{s_i^2}{n_i}$$\n",
    "\n",
    "The confidence interval on the estimated difference is:\n",
    "\n",
    "$$(\\bar{x} - \\bar{y}) \\pm t_{\\frac{1-\\gamma}{2}, \\ \\nu} \\ \\sqrt{\\epsilon_x+\\epsilon_y}$$\n",
    "\n",
    "(The formula for $\\nu$ is known as the Welch–Satterthwaite equation, and $\\nu$ is the *effective degrees of freedom*.  The Welch statistics are not exactly t-distributed, but are close enough for all practical purposes.)\n",
    "\n",
    "### If variances are the same\n",
    "We can get tighter confidence intervals if we know that the variance of *X* and *Y* are the same (because we are estimating just one \"pooled sample variance\" instead of splitting the samples to make two different variance estimates), in which case we can use Student's formulation:\n",
    "$$(\\bar{x} - \\bar{y}) \\pm t_{\\frac{1-\\gamma}{2},n_x+n_y-2} \\left(S_p \\sqrt{\\frac{1}{n_x}+\\frac{1}{n_y}}\\right), \\ \\text{where:} \\ S_p^2 = \\frac{(n_x-1)s_x^2+(n_y-1)s_y^2}{n_x+n_y-2}$$\n",
    "\n",
    "**However:** If this equal-variance assumption is incorrect then the inference will be invalid.  Getting a more significant but erroneous result seems like a bad tradeoff, so *unless you are very confident that variances are equal, use the Welch formulas!*\n",
    "\n",
    "## CI and *p* for one experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples MeanX: 0.07 (n=15)\t MeanY: 0.65 (n=5)\n",
      "\tSample difference of means = -0.58\n",
      "\t p-value=58.9% from t-stat: -0.580, df=4.52\n",
      "90% Confidence Interval on sample difference of means:\n",
      "\t  Welch: [-2.65, 1.48]\n",
      "\tStudent: [-1.76, 0.60]\n"
     ]
    }
   ],
   "source": [
    "# Experimental parameters\n",
    "nX, nY = (15, 5)        # Sample size for each variable\n",
    "meanX, meanY = (0, 0.6) # True mean values\n",
    "sigmaX, sigmaY = (1, 2) # True standard deviations\n",
    "\n",
    "# One experiment:\n",
    "x = np.random.normal(size=nX, loc=meanX, scale=sigmaX)\n",
    "y = np.random.normal(size=nY, loc=meanY, scale=sigmaY)\n",
    "muX = np.mean(x)          # Sample mean of X\n",
    "muY = np.mean(y)          # Sample mean of Y\n",
    "varX = np.var(x, ddof=1)  # Sample variance of X\n",
    "varY = np.var(y, ddof=1)  # Sample variance of Y\n",
    "sampleDiff = (muX - muY)\n",
    "eX = varX / nX\n",
    "eY = varY / nY\n",
    "tstat = sampleDiff / np.sqrt(eX+eY)\n",
    "nu = (eX + eY)**2 / (eX**2 / (nX-1) + eY**2 / (nY-1))\n",
    "p = 2*t.cdf(-abs(tstat), df=nu)  # 2-tailed p value\n",
    "WelchCI = t.interval(gamma, df=nu, loc=sampleDiff, scale=np.sqrt(eX+eY))\n",
    "stp = np.sqrt(((nX-1)*varX + (nY-1)*varY)/(nX+nY-2))  # Student's pooled sample variance\n",
    "StudentCI = t.interval(gamma, df=(nX+nY-2), loc=sampleDiff, scale=(stp*np.sqrt(1/nX+1/nY)))\n",
    "\n",
    "print(f'Samples MeanX: {muX:.2f} (n={nX})\\t MeanY: {muY:.2f} (n={nY})\\n'\n",
    "      f'\\tSample difference of means = {(muX-muY):.2f}\\n'\n",
    "      f'\\t p-value={p:.1%} from t-stat: {tstat:.3f}, df={nu:.2f}\\n'\n",
    "      f'{gamma:.0%} Confidence Interval on sample difference of means:\\n'\n",
    "      f'\\t  Welch: [{WelchCI[0]:.2f}, {WelchCI[1]:.2f}]\\n'\n",
    "      f'\\tStudent: [{StudentCI[0]:.2f}, {StudentCI[1]:.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation to verify *p*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental difference of means was -0.58 with p=58.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50,000 simulations with (nx=15, ny=5) under the null hypothesis:\n",
      "\t29.2% produced a test statistic < -0.58\n",
      "\t28.8% produced a test statistic >  0.58\n",
      "\t58.0% produced a statistic more extreme than the experiment.\n"
     ]
    }
   ],
   "source": [
    "print(f'Experimental difference of means was {(muX-muY):.2f} with p={p:.1%}')\n",
    "numSims = 50_000  # Number of simulations to run\n",
    "leftStat = tstat\n",
    "if leftStat > 0: leftStat = -leftStat\n",
    "count_left = 0\n",
    "count_right = 0\n",
    "for i in range(numSims):\n",
    "    x = np.random.normal(size=nX)  # We're using the same parameters for both variables\n",
    "    y = np.random.normal(size=nY)  # since this is a simulation under the null hypothesis\n",
    "    simMeanX = np.mean(x)\n",
    "    simMeanY = np.mean(y)\n",
    "    simVarX = np.var(x, ddof=1)  # Sample variance of X\n",
    "    simVarY = np.var(y, ddof=1)  # Sample variance of Y\n",
    "    eX = simVarX / nX\n",
    "    eY = simVarY / nY\n",
    "    simStat = (simMeanX - simMeanY) / np.sqrt(eX+eY)\n",
    "    if simStat > 0 and simStat >= -leftStat:\n",
    "        count_right += 1\n",
    "    elif simStat < 0 and simStat <= leftStat:\n",
    "        count_left += 1\n",
    "print(f'Over {numSims:,} simulations with (nx={nX}, ny={nY}) under the null hypothesis:\\n'\n",
    "      f'\\t{count_left/numSims:5.1%} produced a test statistic < {leftStat:.2f}\\n'\n",
    "      f'\\t{count_right/numSims:5.1%} produced a test statistic >  {-leftStat:.2f}\\n'\n",
    "      f'\\t{(count_left+count_right)/numSims:.1%} produced a statistic more extreme than the experiment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation to verify CI formula\n",
    "Here we'll calculate both Welch's and Student's confidence intervals.  Remember: Student's formulas are only valid if the two variables have identical variance (i.e., `sigmaX=sigmaY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50,000 simulations of 15 samples for X and 5 samples for Y,\n",
      "\t\twith sigmaX=1, sigmaY=2 ... i.e., **unequal** variances\n",
      "\tAvg of difference of sample means (muX - muY) = -0.60 vs true value -0.6\n",
      "\tAvg Welch CI width:   3.608\n",
      "\tAvg Student CI width: 2.268\n",
      "\tand the 90% confidence interval contained the true parameter:\n",
      "\t\t89.3% of the time for Welch CI\n",
      "\t\t76.1% of the time for Student CI\n"
     ]
    }
   ],
   "source": [
    "sampleDiff = np.zeros(numSims)    # The test statistic: sample (meanX-meanY)\n",
    "WelchWidth = np.zeros(numSims)    # Width of Welch's confidence interval\n",
    "count_Welch_contains_true = 0     # Simulations in which Welch's CI contains the true statistic\n",
    "StudentWidth = np.zeros(numSims)  # Width of Student's confidence interval\n",
    "count_Student_contains_true = 0   # Simulations in which Student's CI contains true statistic\n",
    "for i in range(numSims):\n",
    "    x = np.random.normal(size=nX, loc=meanX, scale=sigmaX)\n",
    "    y = np.random.normal(size=nY, loc=meanY, scale=sigmaY)\n",
    "    muX = np.mean(x)\n",
    "    muY = np.mean(y)\n",
    "    varX = np.var(x, ddof=1)\n",
    "    varY = np.var(y, ddof=1)\n",
    "    sampleDiff[i] = (muX - muY)\n",
    "    eX = varX / nX\n",
    "    eY = varY / nY\n",
    "    nu = (eX + eY)**2 / (eX**2 / (nX-1) + eY**2 / (nY-1))\n",
    "    # Welch's CI:\n",
    "    CI = t.interval(gamma, df=nu, loc=sampleDiff[i], scale=np.sqrt(eX+eY))\n",
    "    WelchWidth[i] = CI[1] - CI[0]\n",
    "    if CI[0] < meanX-meanY < CI[1]:\n",
    "        count_Welch_contains_true += 1\n",
    "    # Student's CI (assuming sigmaX=sigmaY)\n",
    "    varP = ((nX-1)*varX + (nY-1)*varY)/(nX+nY-2)  # Pooled sample variance\n",
    "    CI = t.interval(gamma, df=(nX+nY-2), loc=sampleDiff[i], scale=np.sqrt(varP * (1/nX + 1/nY)))\n",
    "    StudentWidth[i] = CI[1] - CI[0]\n",
    "    if CI[0] < meanX-meanY < CI[1]:\n",
    "        count_Student_contains_true += 1\n",
    "\n",
    "print(f'Over {numSims:,} simulations of {nX} samples for X and {nY} samples for Y,\\n'\n",
    "      f'\\t\\twith sigmaX={sigmaX}, sigmaY={sigmaY} ... i.e., {\"equal\" if (sigmaX==sigmaY) else \"**unequal**\"} variances\\n'\n",
    "      f'\\tAvg of difference of sample means (muX - muY) = {np.mean(sampleDiff):.2f} vs true value {(meanX-meanY)}\\n'\n",
    "      f'\\tAvg Welch CI width:   {np.mean(WelchWidth):.3f}\\n'\n",
    "      f'\\tAvg Student CI width: {np.mean(StudentWidth):.3f}\\n'\n",
    "      f'\\tand the {gamma:.0%} confidence interval contained the true parameter:\\n'\n",
    "      f'\\t\\t{count_Welch_contains_true / numSims:.1%} of the time for Welch CI\\n'\n",
    "      f'\\t\\t{count_Student_contains_true / numSims:.1%} of the time for Student CI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio of Sigmas\n",
    "\n",
    "We want to know whether the precision of two gun systems is different.\n",
    "\n",
    "If we believe that $\\sigma_x \\approx \\sigma_y$ then we can model the dispersion of shots with the Rayleigh distribution.  We also know that the Rayleigh parameter $\\sigma$ is effectively a standard deviation, $\\sigma^2$ is a variance, and we saw that a ratio of variances is modelled by the F distribution.  Indeed, for two Rayleigh estimates we have the test statistic:\n",
    "$$\\left(\\frac{\\hat{\\sigma_a}}{\\hat{\\sigma_b}} \\right)^2 \\sim F(2n_a, 2n_b)$$\n",
    "\n",
    "However, the coordinates of shots on a target aren't Rayleigh distributed until we know their center.  And though we like to think that with a properly zeroed gun the Point of Aim is the true center, we know that in general there is always some zero error.  So for each group we have to estimate the center as the mean value of the *x-* and *y-* coordinates, and then compute the sample radii as $r_i = \\sqrt{(x_i-\\bar{x})^2+(y_i-\\bar{y})^2}$, and then those sample radii are Rayleigh distributed.\n",
    "\n",
    "If $A, B$ are Rayleigh distributed, and to compute the sample radii we have to estimate $g$ group centers, then the test statistic for a difference is the unbiased ratio of mean radii squared, which is distributed as:\n",
    "$$\\left(\\frac{\\hat{\\sigma_a}}{\\hat{\\sigma_b}} \\cdot \\frac{c_{G_b}}{c_{G_a}}\\right)^2 = \\frac{(n_b-g_b) \\sum a^2}{(n_a-g_a) \\sum b^2} \\sim F(2(n_a-g_a), 2(n_b-g_b))$$\n",
    "\n",
    "(Shown on the left-hand side are two different formulas for the test statistic: We can work backwards from the sigma estimates by removing the $c_G$ correction terms and squaring.  Or we can adjust the mean of sample radii squared by the degrees of freedom.)\n",
    "\n",
    "The confidence interval on the test is:\n",
    "$$\\left(\\frac{\\hat{\\sigma_a}}{\\hat{\\sigma_b}} \\cdot \\frac{c_{G_b}}{c_{G_a}}\\right) \\ \\times \\left[\\frac{1}{\\sqrt{F_{\\frac{1+\\gamma}{2}}(2(n_a-g_a), 2(n_b-g_b))}}, \\frac{1}{\\sqrt{F_{\\frac{1-\\gamma}{2}}(2(n_a-g_a), 2(n_b-g_b))}} \\right]$$\n",
    "\n",
    "(Note: If $n_a=n_b$ then the correction terms $c_G$ cancel and can be omitted.  If the sample sizes are large then the correction terms are negligible – see [the $c_G(n)$ values above](#estimating-standard-deviation-sd).)\n",
    "\n",
    "## CI and *p* for one experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples sigmaA: 1.43 (n=1x10)\t sigmaB: 1.04 (n=2x3)\n",
      "\tSample Sigma Ratio: 1.37\t(True Ratio: 1.5)\n",
      "\tSample Ratio Squared: 1.95\n",
      "90% Confidence Interval on Sample Ratio: [0.78, 2.21]\n",
      "\t p left=11.4%, p right=16.9%, p value=28.3%\n"
     ]
    }
   ],
   "source": [
    "nA, nB = (10, 3)  # Experimental parameters – shots per group\n",
    "gA, gB = (1, 2)   # Experimental parameters - # of groups\n",
    "true_param = 1.5    # True parameter: sigmaA/sigmaB\n",
    "gamma = 0.9   # Confidence level for Confidence Intervals\n",
    "\n",
    "def groupSumR2(shots: list[tuple[float, float]]) -> float:\n",
    "    \"\"\"Given a list of shot coordinates [x,y], return sample sum squared radius\"\"\"\n",
    "    n = len(shots)\n",
    "    sumR2 = xbar = ybar = 0\n",
    "    for i in range(n):\n",
    "        xbar += shots[i, 0]\n",
    "        ybar += shots[i, 1]\n",
    "    xbar /= n\n",
    "    ybar /= n\n",
    "    for i in range(n):\n",
    "        sumR2 += (shots[i, 0] - xbar)**2 + (shots[i, 1] - ybar)**2\n",
    "    return sumR2\n",
    "\n",
    "def sigmaEstimate(g: int, n: int, groups: list[list[tuple[float, float]]]) -> tuple[float, float, float]:\n",
    "    \"\"\"Given g groups of n shots per group,\n",
    "        return (aggregated estimate of sigma, sum sample radius squared, cG)\"\"\"\n",
    "    sumR2 = 0\n",
    "    degrees = 2*(n-1)*g\n",
    "    cG = cGauss(degrees+1)\n",
    "    for group in range(g):\n",
    "        sumR2 += groupSumR2(groups[group])\n",
    "    estimate = cG * math.sqrt(sumR2 / degrees)\n",
    "    return estimate, sumR2, cG\n",
    "\n",
    "shotsA = np.random.normal(scale = true_param, size=(gA, nA, 2))\n",
    "shotsB = np.random.normal(scale = 1, size=(gB, nB, 2))\n",
    "sigmaA, sumR2A, cG_A = sigmaEstimate(gA, nA, shotsA)\n",
    "sigmaB, sumR2B, cG_B = sigmaEstimate(gB, nB, shotsB)\n",
    "\n",
    "A2 = sumR2A/(gA*nA-gA)  # Unbiased mean value of A^2\n",
    "B2 = sumR2B/(gB*nB-gB)  # Unbiased mean value of B^2\n",
    "R2Ratio = A2/B2\n",
    "p_left = f.cdf(R2Ratio if R2Ratio <= 1 else 1/R2Ratio, 2*gA*(nA-1), 2*gB*(nB-1))\n",
    "p_right = 1-f.cdf(R2Ratio if R2Ratio >= 1 else 1/R2Ratio, 2*gA*(nA-1), 2*gB*(nB-1))\n",
    "\n",
    "sigmaRatio = sigmaA/sigmaB\n",
    "cRatio = cG_B/cG_A\n",
    "root_statistic = sigmaRatio*cRatio\n",
    "CU = root_statistic/math.sqrt(f.ppf((1-gamma)/2, 2*gA*(nA-1), 2*gB*(nB-1)))  # Upper bound of confidence interval\n",
    "CL = root_statistic/math.sqrt(f.ppf((1+gamma)/2, 2*gA*(nA-1), 2*gB*(nB-1)))  # Lower bound of confidence interval\n",
    "\n",
    "print(f'Samples sigmaA: {sigmaA:.2f} (n={gA}x{nA})\\t sigmaB: {sigmaB:.2f} (n={gB}x{nB})\\n'\n",
    "      f'\\tSample Sigma Ratio: {sigmaRatio:.2f}\\t(True Ratio: {true_param})\\n'\n",
    "      f'\\tSample Ratio Squared: {R2Ratio:.2f}\\n'\n",
    "      f'{gamma:.0%} Confidence Interval on Sample Ratio: [{CL:.2f}, {CU:.2f}]\\n'\n",
    "      f'\\t p left={p_left:.1%}, p right={p_right:.1%}, p value={p_left+p_right:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation to verify *p*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the experimental sigma ratio 1.37 and its inverse 0.73:\n",
      "\tthe unbiased squared ratio is 1.95 and its inverse 0.51:\n",
      "\tF-dist gives p left tail = 11.4%, right tail = 16.9%, sum=28.3%\n",
      "Over 50,000 simulations with (nA=1x10, nB=2x3) using the null hypothesis:\n",
      "\t11.4% produced a variance ratio < 0.51\n",
      "\t16.9% produced a variance ratio > 1.95\n",
      "\t28.3% produced a statistic more extreme than the experiment.\n"
     ]
    }
   ],
   "source": [
    "numSims = 50_000\n",
    "print(f'For the experimental sigma ratio {sigmaRatio:.2f} and its inverse {1/sigmaRatio:.2f}:')\n",
    "print(f'\\tthe unbiased squared ratio is {R2Ratio:.2f} and its inverse {1/R2Ratio:.2f}:')\n",
    "print(f'\\tF-dist gives p left tail = {p_left:.1%}, right tail = {p_right:.1%},'\n",
    "      f' sum={p_right+p_left:.1%}')\n",
    "sample_ratio = R2Ratio  # Ratio from single experiment above\n",
    "if sample_ratio < 1:  # Reference value will be the ratio in terms > 1\n",
    "    sample_ratio = 1/sample_ratio\n",
    "count_left = 0\n",
    "count_right = 0\n",
    "for i in range(numSims):\n",
    "    samplesA = np.random.normal(size=(gA, nA, 2))  # We're using the same distribution for both variables\n",
    "    samplesB = np.random.normal(size=(gB, nB, 2))  # since this is a simulation under the null hypothesis\n",
    "    simSigmaA, simSumR2A, sim_cG_A = sigmaEstimate(gA, nA, samplesA)\n",
    "    simSigmaB, simSumR2B, sim_cG_B = sigmaEstimate(gB, nB, samplesB)\n",
    "    simR2Ratio = ((simSigmaA*sim_cG_B)/(simSigmaB*sim_cG_A))**2\n",
    "    # Alternate formula for test statistic:\n",
    "    # A2 = simSumR2A/(gA*nA-gA)\n",
    "    # B2 = simSumR2B/(gB*nB-gB)\n",
    "    # simR2Ratio = A2/B2\n",
    "    if simR2Ratio > 1 and simR2Ratio >= sample_ratio:\n",
    "        count_right += 1\n",
    "    elif simR2Ratio < 1 and simR2Ratio <= 1/sample_ratio:\n",
    "        count_left += 1\n",
    "print(f'Over {numSims:,} simulations with (nA={gA}x{nA}, nB={gB}x{nB}) using the null hypothesis:\\n'\n",
    "      f'\\t{count_left/numSims:5.1%} produced a variance ratio < {1/sample_ratio:.2f}\\n'\n",
    "      f'\\t{count_right/numSims:5.1%} produced a variance ratio > {sample_ratio:.2f}\\n'\n",
    "      f'\\t{(count_left+count_right)/numSims:.1%} produced a statistic more extreme than the experiment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation to verify CI formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50,000 simulations with (nA=1x12, nB=4x3),\n",
      "\tthe 90% CI contained the true parameter 90.2% of the time.\n"
     ]
    }
   ],
   "source": [
    "numSims = 50_000\n",
    "nA, nB = (12, 3)  # Experimental parameters – shots per group\n",
    "gA, gB = (1, 4)   # Experimental parameters - # of groups\n",
    "true_param = 1.5  # True parameter: sigmaA/sigmaB\n",
    "gamma = 0.9   # Confidence level for Confidence Intervals\n",
    "\n",
    "def sigmaRatioExperiment():\n",
    "    shotsA = np.random.normal(scale = true_param, size=(gA, nA, 2))\n",
    "    shotsB = np.random.normal(scale = 1, size=(gB, nB, 2))\n",
    "    sigmaA, _, cG_A = sigmaEstimate(gA, nA, shotsA)\n",
    "    sigmaB, _, cG_B = sigmaEstimate(gB, nB, shotsB)\n",
    "    sigmaRatio = sigmaA/sigmaB\n",
    "    cRatio = cG_B/cG_A\n",
    "    return sigmaRatio, cRatio\n",
    "\n",
    "FU = 1/math.sqrt(f.ppf((1-gamma)/2, 2*gA*(nA-1), 2*gB*(nB-1)))  # Upper bound of F dist\n",
    "FL = 1/math.sqrt(f.ppf((1+gamma)/2, 2*gA*(nA-1), 2*gB*(nB-1)))  # Lower bound of F dist\n",
    "count_contains_true = 0  # Number of simulations in which CI contains true parameter\n",
    "\n",
    "for i in range(numSims):\n",
    "    sampleRatio, cRatio = sigmaRatioExperiment()\n",
    "    CL = sampleRatio * cRatio * FL\n",
    "    CU = sampleRatio * cRatio * FU\n",
    "    if CL < true_param < CU:\n",
    "        count_contains_true += 1\n",
    "\n",
    "print(f'Over {numSims:,} simulations with (nA={gA}x{nA}, nB={gB}x{nB}),\\n\\t'\n",
    "      f'the {gamma:.0%} CI contained the true parameter {count_contains_true / numSims:.1%} of the time.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
